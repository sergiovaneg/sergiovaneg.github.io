---
title: "Fractal Art (AoC 2017, Day 21)"
date: 2024-05-15
categories: Go, AoC
---
## Table of Contents

1. [A Little Background (feel free to skip it)](#a-little-background)
2. [The Problem](#the-problem)
3. [The Naïve Approach](#naive)
4. [$O(C^{2k})$, and why we can't have Nice Things](#nice_things)

## A Little Background

I really like programming. Just coding for the sake of doing so is something I truly enjoy. I know that a large amount of people in the IT industry share this feeling, or at least they might have when they first got into this field. But as a doctoral ML researcher, I don't have to deal with the downsides of industry programming, such as working with the unmaintainable clusterfuck of a codebase an intern wrote before I was hired or [trying to explain to a PM why it's taken 3 weeks to display the user's birthday date on the setting page](https://youtu.be/y8OnoxKotPQ?si=08w9b5LZKoarjGol). My code is my domain, and I am free to develop it as I see fit or to burn it down and rebuild it from its ashes at my discretion; all my supervisors care about is that the error metrics go down and that the inference time goes *Brrr*.

However, being an ML researcher means the scope of technologies I can use is pretty narrow, especially when it comes to programming languages. Sure, I could write my own kernels in CUDA C++, or perhaps delve into Julia for some multiple-dispatch array programming with JIT compilation. However, I am not capable of iterating over model configurations and algorithms at the pace my job requires in C++ (skill-issued much?), and honestly speaking Julia does not provide a big-enough improvement in model performance w.r.t. Python to justify losing access to the data pre-processing, parameter tuning, and visualization stacks I rely on.

This does not mean I am stuck with the standard at every step; in fact, I use JAX/Keras because of its functional and JIT compilation APIs, even if most authors in the literature implement their papers using PyTorch. However, every deviation from the convention requires an investment in time, which in my case has been having to re-implement the models I could've just grabbed from the public repos. This is time for which I am getting paid, and there are deadlines I have to meet, so going against the current at every step is just plain irresponsible.

Now, don't get me wrong: I really like programming in Python, and I enjoy my job. Nevertheless, I understand the reason I am getting paid to do something is because I cannot just quit whenever I get bored with repetitive tasks or lose interest on the topic I'm working with. Therefore, to nurture and preserve my love for programming, I mix my daily tasks with coding exercises in languages I would not be able to use in my daily job.

This is where [Advent of Code](https://adventofcode.com/about) (AoC)comes into play: a yearly set of 25 themed puzzles, increasing in complexity as Christmas gets closer, solvable in [any programming language](https://github.com/kalintas/aoc-2023) (and I really mean [any](https://youtu.be/xnNkiaHZrGU?si=x2DVs3zQROzEcUYu)) or even by hand. Since answers are requested as a number or a string, AoC does not coerce you into a specific algorithm or data structure. However, AoC puzzles have the particularity of being 2-fold, where the second part usually becomes unfeasible in reasonable time/memory if it is not approached cleverly. This allows for [rather riveting optimizations](https://blog.singleton.io/posts/2024-01-07-more-advent-of-code-optimization/) and [creative personal challenges](https://programsareproofs.com/articles/aoc_2021.html). AoC draws a truly passionate community of developers, and this write-up is my first attempt at becoming an active part of it.

There is nothing inherently different about the problem in this post. However, this was the first time I felt all the techniques I had to learn while solving AoC questions came naturally to me as I was reading the question. I will first go through the problem structure, the naïve solution, the problems with it, and the optimization steps I took to reach my current best. Keep in mind I implemented my solution in [Go](https://go.dev/) which, even if compiled, relies on a runtime with a garbage collector, so I am sure further optimizations can be done by using a manually managed language like [Zig](https://ziglang.org/) or [Rust](https://www.rust-lang.org/).

## The Problem

The full description can be found [here](https://adventofcode.com/2017/day/21). Picture a square grid ($n \times n$) containing one of two ASCII characters, namely `-` and `#`, and starting as:

|   |   |   |
| - | - | - |
| . | # | . |
| . | . | # |
| # | # | # |

We are told that this grid will evolve by applying one of two conditional procedures:

1. If the size of the grid is evenly divisible by 2, break it up into 2x2 squares and convert each 2x2 square into a 3x3 square by following the corresponding enhancement rule.
2. Otherwise, the size is evenly divisible by 3; break the grid up into 3x3 squares, and convert each 3x3 square into a 4x4 square by following the corresponding enhancement rule.

The aforementioned rules are passed to us as an input of the form

```text
../.# => ##./#../...
.#./..#/### => #..#/..../..../#..#
```

where patterns are flattened and rows are separated using `/`. For example, the first line of the above ruleset indicates a transformation from

|   |   |
| - | - |
| . | . |
| . | # |

to

|   |   |   |
| - | - | - |
| # | # | . |
| # | . | . |
| . | . | . |

However, there's a catch: not all possible input patterns are given. "Source" subgrids, hereinafter referred to as *Fractals*, are assumed to be invariant to mirroring (vertical and horizontal) and rotation (90°) operations, meaning that if one can be turned into the other via a sequence of these elemental operations, they are considered equal. The result of the transformation, however, should remain as provided regardless of the transformations applied to the original pattern.

Given the rule set, calculate how many `#`s will be in the grid after 5 and 18 iterations for parts 1 and 2 of the puzzle respectively.

## <a name="naive"></a>The Naïve Approach

*Fractal Art* falls into the category of AoC puzzles that provide explicit instructions on how to reach a solution. As we will later see, this is usually an early warning of the direct implementation being computationally prohibitive. Nevertheless, for completeness' sake we will go over it.

The first step is to parse the input. As a sequence of input/output pairs with distinct input fractals, it follows that the natural structure to store the rule set is a hash-map. Since in Go, slices (i.e., arrays of unknown size) are not hashable, we use the flattened pattern strings as keys and the expanded fractals as values. This results in the following type definitions and function signatures (trivial implementation):

```go
const SEED = ".#./..#/###"

type Fractal [][]byte
type Ruleset map[string]Fractal

func (f Fractal) serialize() string
func deserialize(serial string) Fractal
```

The next step is to match an incoming pattern with our rule set. The simplest way to do so is to generate all equivalent fractals, which can be achieved by mirroring the fractal once (either vertically or horizontally) and then rotating both versions 3 times in the same direction (clockwise or anti-clockwise) for a total of 8 fractals, and checking their signatures (flattened string representation) in our rule set. Since we are told only one invariant is registered, we grab the first one found in the hash-map.

The above operation is implemented in the `transform` function as follows:

```go
func makeEmpty(n int) Fractal {
 f := make(Fractal, n)
 for i := range n {
  f[i] = make([]byte, n)
 }
 return f
}

func (f Fractal) mirror() Fractal {
 fNew := make(Fractal, len(f))

 for i, row := range f {
  fNew[i] = slices.Clone(row)
  slices.Reverse(fNew[i])
 }

 return fNew
}

func (f Fractal) rotate() Fractal {
 n := len(f)
 fNew := makeEmpty(n)

 for i := range n {
  for j := range n {
   fNew[i][j] = f[j][n-i-1]
  }
 }

 return fNew
}

func (r Ruleset) transform(f Fractal) Fractal {
 fm := f.mirror()

 for range 4 {
  if aux, ok := r[f.serialize()]; ok {
   return aux
  }

  if aux, ok := r[fm.serialize()]; ok {
   return aux
  }

  f = f.rotate()
  fm = fm.rotate()
 }

 return nil
}
```

## <a name="nice_things"></a>$O(C^{2k})$, and why we can't have Nice Things

The naïve implementation turns out to slow down quite a bit for the second part, meaning that the grid is growing beyond a manageable size; but just how big is it? Well, since the rules are strictly incremental, i.e. subgrids grow in size for every iteration. Let $n_k$ be the side-length of the grid at iteration $k$; then, written as a recursion,

$$\begin{split}
n_0 &= 3
\\
n_{k+1} &= \begin{cases}
\frac{3}{2} \cdot n_k \quad & \text{if } n_k \text{ even}
\\
\frac{4}{3} \cdot n_k \quad & \text{otherwise}
\end{cases}
\\ & \implies \left(\frac{4}{3} \right)^k \le \frac{n_k}{3} \le \left(\frac{3}{2} \right)^k
\end{split}$$

If math alone isn't scary enough, let's take a look at some numbers:

| $k$ | $n_k$ | Size in Memory |
| :-: | :-: | :-: |
| 0 | 3 | 9 B |
| 1 | 4 | 16 B |
| 2 | 6 | 36 B |
| 3 | 9 | 81 B |
| 4 | 12 | 144 B |
| 5 | 18 | 324 B |
| 6 | 27 | 729 B |
| 7 | 36 | 1.27 kB |
| $\vdots$ | $\vdots$ | $\vdots$ |
| 10 | 108 | 11.4 kiB |
| $\vdots$ | $\vdots$ | $\vdots$ |
| 13 | 324 | 103 kiB |
| $\vdots$ | $\vdots$ | $\vdots$ |
| 16 | 972 | 923 kiB |
| 17 | 1458 | 2.03 MiB |
| 18 | 2187 | 4.56 MiB |

So while in the first part we had to handle a 36B array, for part 2 we are allocating 4.5MiB of memory, which is a million-plus-fold increase in the number of elements.
