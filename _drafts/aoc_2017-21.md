---
title: "Fractal Art (AoC 2017, Day 21)"
date: 2024-05-15
categories: Go, AoC
---
## Table of Contents

1. [A Little Background (feel free to skip it)](#a-little-background)
2. [The Problem](#the-problem)
3. [The Naïve Approach](#naive)
4. [$O(C^{2k})$, and why we can't have Nice Things](#nice_things)

## A Little Background

I really like programming. Just coding for the sake of doing so is something I truly enjoy. I know that a large amount of people in the IT industry share this feeling, or at least they might have when they first got into this field. But as a doctoral ML researcher, I don't have to deal with the downsides of industry programming, such as working with the unmaintainable clusterfuck of a codebase an intern wrote before I was hired or [trying to explain to a PM why it's taken 3 weeks to display the user's birthday date on the setting page](https://youtu.be/y8OnoxKotPQ?si=08w9b5LZKoarjGol). My code is my domain, and I am free to develop it as I see fit or to burn it down and rebuild it from its ashes at my discretion; all my supervisors care about is that the error metrics go down and that the inference time goes *Brrr*.

However, being an ML researcher means the scope of technologies I can use is pretty narrow, especially when it comes to programming languages. Sure, I could write my own kernels in CUDA C++, or perhaps delve into Julia for some multiple-dispatch array programming with JIT compilation. However, I am not capable of iterating over model configurations and algorithms at the pace my job requires in C++ (skill-issued much?), and honestly speaking Julia does not provide a big-enough improvement in model performance w.r.t. Python to justify losing access to the data pre-processing, parameter tuning, and visualization stacks I rely on.

This does not mean I am stuck with the standard at every step; in fact, I use JAX/Keras because of its functional and JIT compilation APIs, even if most authors in the literature implement their papers using PyTorch. However, every deviation from the convention requires an investment in time, which in my case has been having to re-implement the models I could've just grabbed from the public repos. This is time for which I am getting paid, and there are deadlines I have to meet, so going against the current at every step is just plain irresponsible.

Now, don't get me wrong: I really like programming in Python, and I enjoy my job. Nevertheless, I understand the reason I am getting paid to do something is because I cannot just quit whenever I get bored with repetitive tasks or lose interest on the topic I'm working with. Therefore, to nurture and preserve my love for programming, I mix my daily tasks with coding exercises in languages I would not be able to use in my daily job.

This is where [Advent of Code](https://adventofcode.com/about) (AoC)comes into play: a yearly set of 25 themed puzzles, increasing in complexity as Christmas gets closer, solvable in [any programming language](https://github.com/kalintas/aoc-2023) (and I really mean [any](https://youtu.be/xnNkiaHZrGU?si=x2DVs3zQROzEcUYu)) or even by hand. Since answers are requested as a number or a string, AoC does not coerce you into a specific algorithm or data structure. However, AoC puzzles have the particularity of being 2-fold, where the second part usually becomes unfeasible in reasonable time/memory if it is not approached cleverly. This allows for [rather riveting optimizations](https://blog.singleton.io/posts/2024-01-07-more-advent-of-code-optimization/) and [creative personal challenges](https://programsareproofs.com/articles/aoc_2021.html). AoC draws a truly passionate community of developers, and this write-up is my first attempt at becoming an active part of it.

There is nothing inherently different about the problem in this post. However, this was the first time I felt all the techniques I had to learn while solving AoC questions came naturally to me as I was reading the question. I will first go through the problem structure, the naïve solution, the problems with it, and the optimization steps I took to reach my current best. Keep in mind I implemented my solution in [Go](https://go.dev/) which, even if compiled, relies on a runtime with a garbage collector, so I am sure further optimizations can be done by using a manually managed language like [Zig](https://ziglang.org/) or [Rust](https://www.rust-lang.org/).

## The Problem

The full description can be found [here](https://adventofcode.com/2017/day/21). Picture a square grid ($N \times N$) containing one of two ASCII characters, namely `-` and `#`, and starting as:

|   |   |   |
| - | - | - |
| . | # | . |
| . | . | # |
| # | # | # |

We are told that this grid will evolve by applying one of two conditional procedures:

1. If the size of the grid is evenly divisible by 2, break it up into 2x2 squares and convert each 2x2 square into a 3x3 square by following the corresponding enhancement rule.
2. Otherwise, the size is evenly divisible by 3; break the grid up into 3x3 squares, and convert each 3x3 square into a 4x4 square by following the corresponding enhancement rule.

The aforementioned rules are passed to us as an input of the form

```text
../.# => ##./#../...
.#./..#/### => #..#/..../..../#..#
```

where patterns are flattened and rows are separated using `/`. For example, the first line of the above ruleset indicates a transformation from

|   |   |
| - | - |
| . | . |
| . | # |

to

|   |   |   |
| - | - | - |
| # | # | . |
| # | . | . |
| . | . | . |

However, there's a catch: not all possible input patterns are given. "Source" subgrids, hereinafter referred to as *Fractals*, are assumed to be invariant to mirroring (vertical and horizontal) and rotation (90°) operations, meaning that if one can be turned into the other via a sequence of these elemental operations, they are considered equal. The result of the transformation, however, should remain as provided regardless of the transformations applied to the original pattern.

Given the rule set, calculate how many `#`s will be in the grid after 5 and 18 iterations for parts 1 and 2 of the puzzle respectively.

## <a name="naive"></a>The Naïve Approach

*Fractal Art* falls into the category of AoC puzzles that provide explicit instructions on how to reach a solution. As we will later see, this is more often than not an early warning of the direct implementation being computationally prohibitive. Nevertheless, for completeness' sake we will go over it.

### Naïve Representation

The first step is to parse the input. As a sequence of input/output pairs with distinct input fractals, it follows that the natural structure to store the rule set is a hash-map. Since in Go, slices (i.e., arrays of unknown size) are not hashable, we use the flattened pattern strings as keys and the expanded fractals as values. This results in the following type definitions and function signatures (trivial implementations omitted):

```go
type naiveFractal [][]byte
type naiveRuleset map[string]naiveFractal

func (f naiveFractal) serializeNaive() string
func deserializeNaive(serial string) naiveFractal

func initNaiveRuleset(lines []string) naiveRuleset {
 r := make(naiveRuleset)

 for _, line := range lines {
  kv := strings.Split(line, " => ")
  r[kv[0]] = deserializeNaive(kv[1])
 }

 return r
}
```

### Naïve Matching

The next step is to match an incoming pattern with our rule set. The simplest way to do so is to generate all equivalent fractals, which can be achieved by mirroring the fractal once (either vertically or horizontally) and then rotating both versions 3 times in the same direction (clockwise or anti-clockwise) for a total of 8 fractals, and checking their signatures (flattened string representation) in our rule set. Since we are told only one invariant is registered, we grab the first one found in the hash-map.

The above strategy is implemented in the `transform` function as follows:

```go
func makeEmptyNaive(n int) naiveFractal

func (f naiveFractal) mirror() naiveFractal {
 fNew := make(naiveFractal, len(f))

 for i, row := range f {
  fNew[i] = slices.Clone(row)
  slices.Reverse(fNew[i])
 }

 return fNew
}

func (f naiveFractal) rotate() naiveFractal {
 n := len(f)

 fNew := makeEmptyNaive(n)

 for i := range n {
  for j := range n {
   fNew[i][j] = f[j][n-i-1]
  }
 }

 return fNew
}

func (r naiveRuleset) transform(f naiveFractal) naiveFractal {
 fm := f.mirror()

 for range 4 {
  if aux, ok := r[f.serializeNaive()]; ok {
   return aux
  }

  if aux, ok := r[fm.serializeNaive()]; ok {
   return aux
  }

  f = f.rotate()
  fm = fm.rotate()
 }

 return nil
}
```

### Sub-Indexing & Growth

We define a getter/setter pair that will allow us to query and modify square subregions from the grid; namely:

```go
func (f naiveFractal) getSubfractal(i, j, n int) naiveFractal {
 subFractal := makeEmptyNaive(n)

 for k := range n {
  copy(subFractal[k], f[n*i+k][n*j:])
 }

 return subFractal
}

func (f *naiveFractal) setSubfractal(i, j, n int, sf naiveFractal) {
 for k := range n {
  copy((*f)[n*i+k][n*j:], sf[k])
 }
}
```

Here we split the main fractal into $n$-by-$n$ sub-fractals and select the ($i$-th,$j$-th) square. Then, since an iteration of the requested procedure increases the size of the grid deterministically, we can pre-allocate the resulting fractal and fill it using the above helper methods. Thus, an iteration is implemented as follows:

```go
func (r naiveRuleset) grow(f naiveFractal) naiveFractal {
 n := len(f)

 var s0, s1 int
 if n%2 == 0 {
  s0, s1 = 2, 3
 } else {
  s0, s1 = 3, 4
 }

 nSubfrac := n / s0
 fNext := makeEmptyNaive(nSubfrac * s1)

 for i := range nSubfrac {
  for j := range nSubfrac {
   fNext.setSubfractal(
    i, j, s1,
    r.transform(f.getSubfractal(i, j, s0)))
  }
 }

 return fNext
}
```

### Putting it all together

Now all we need

```go
func (f naiveFractal) count() int {
 var res int

 for _, row := range f {
  for _, v := range row {
   if v == '#' {
    res++
   }
  }
 }

 return res
}

// Syntactic sugar to allow multiple implementations of the 'Solve' method
type NaiveSolver struct{}

func (NaiveSolver) Solve(seed string, nIters int, lines []string) int {
 r := initNaiveRuleset(lines)
 f := deserializeNaive(seed)

 for range nIters {
  if runParallel {
   f = r.growParallel(f)
  } else {
   f = r.grow(f)
  }
 }

 return f.count()
}
```

We also jump ahead for a second and define the following interface to facilitate testing:

```go
type Solver interface {
 Solve(string, int, []string) int
}
```

## <a name="nice_things"></a>$O(C^{2k})$, and how to observe it

The naïve implementation turns out not to slow down as much as I expected for the second part, meaning that the grid is within a manageable size; but just how big is it? Well, let $n_k$ be the side-length of the grid at iteration $k$; then, written as a recursion,

$$\begin{split}
N_0 &= 3
\\
N_{k+1} &= \begin{cases}
\frac{3}{2} \cdot N_k \quad & \text{if } N_k \text{ even}
\\
\frac{4}{3} \cdot N_k \quad & \text{otherwise}
\end{cases}
\\ & \implies \left(\frac{4}{3} \right)^k \le \frac{N_k}{3} \le \left(\frac{3}{2} \right)^k
\end{split}$$

If math alone isn't scary enough, let's take a look at some numbers:

| $k$ | $n_k$ | Size in Memory |
| :-: | :-: | :-: |
| 0 | 3 | 9 B |
| 1 | 4 | 16 B |
| 2 | 6 | 36 B |
| 3 | 9 | 81 B |
| 4 | 12 | 144 B |
| 5 | 18 | 324 B |
| 6 | 27 | 729 B |
| 7 | 36 | 1.27 kB |
| $\vdots$ | $\vdots$ | $\vdots$ |
| 10 | 108 | 11.4 kiB |
| $\vdots$ | $\vdots$ | $\vdots$ |
| 13 | 324 | 103 kiB |
| $\vdots$ | $\vdots$ | $\vdots$ |
| 16 | 972 | 923 kiB |
| 17 | 1458 | 2.03 MiB |
| 18 | 2187 | 4.56 MiB |

So while in the first part we had to handle a 36B array, for part 2 we are allocating 4.5MiB of memory, which is a million-plus-fold increase in the number of elements. But alas, even if inefficient, computer hardware nowadays is good enough so that even my cheap-ass Huawei laptop can just brute-force a 2017 puzzle.

Being day 21, I was expecting it not to be able to scale for part 2, which is why I will admit I didn't even try the brute-force implementation until I started writing this blog. However, it is worth noting that problems back then didn't blow up in complexity so spectacularly as the ones we've gotten in recent years (I'm looking at you specifically, [*Step Counter*](https://adventofcode.com/2023/day/21)). Therefore, in order to observe a measurable effect from any introduced optimizations, let's see how many iterations does it take to get to a nice round runtime; say, a minute:
